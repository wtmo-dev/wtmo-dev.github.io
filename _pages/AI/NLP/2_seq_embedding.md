---
title: "2. Sequence embedding"
tags:
    - NLP
    - sequence embedding
date: "2023-12-12"
thumbnail: "/assets/img/thumbnail/logo.jpg"
---

# Seq2Seq
---
중심 단어와 주변 단어를 통한 예측 기반의 학습법  

# ELMO
---
주변 단어를 보고 중심 단어를 예측하는 방법

# Transformer
---
중심 단어를 보고 주변 단어를 예측하는 방법(학습 횟수가 많음)

# GPT
---
<>으로 단어를 구분하고 n-gram을 통하여 단어를 나눠서 학습한다  
skip-gram과 유사한 학습법  
sub word들을 학습해 유사한 단어학습이 가능

# BERT
---
기존의 LSA(Latent Semantic Analysis)는 문서에서 단어의 빈도를 기준으로 차원축소를 하는 방법론 -> 단어 의미 유추에 약함  
